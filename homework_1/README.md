## 1. Вас пригласили настроить мониторинг на проект. На онбординге вам рассказали, что проект представляет из себя платформу для вычислений с выдачей текстовых отчетов, которые сохраняются на диск. Взаимодействие с платформой осуществляется по протоколу http. Также вам отметили, что вычисления загружают ЦПУ. Какой минимальный набор метрик вы выведите в мониторинг и почему?

**Ответ:**

 Минимальный набор метрик для мониторинга, согласно подходу SRE мы не должны снимать лишние метрики и усложнять систему, поэтому достаточно для данной задачи следующее:
 
- **Приложение**:
  -	HTTP-статусы (2xx, 4xx, 5xx)
  - Среднее время обработки запроса (Latency)
  - Внутренние ошибки (логи приложения)
   
- **Инфраструктура**:
  -	Загрузка CPU (в %)
  -	Свободное место на диске (Disk Space)
  - Количество запросов в секунду (Request Rate CPU)
  - Загруженность сетевых интерфейсов (Bits received, Bits send) 
  - Использование оперативной памяти (RAM, % или MB/GB)

Этого будет достаточно для данного проекта, но можно добавить метрику состояния диска: I/O wait или disk latency, чтобы вовремя выявить деградацию диска и понять что именно тормозит приложение, диск или CPU.


## 2. Менеджер продукта, посмотрев на ваши метрики, сказал, что ему непонятно, что такое RAM/inodes/CPUla. Также он сказал, что хочет понимать, насколько мы выполняем свои обязанности перед клиентами и какое качество обслуживания. Что вы можете ему предложить?

**Ответ:**


Наша задача - перевести технические метрики в бизнес-язык и показать, как мы будем выполняеть обязательства перед пользователями. В первую очередь я бы дал пояснения по поводу каждой метрики, например: "Мы мониторим свободное место на диске (Disk Space), потому что если оно закончится сервис упадет и ваши отчеты перестанут сохранятся", и так далее. 

### Предложим дэшборд на основе SLI/SLO:

## Ключевые SLI, ключевые бизнес-показатели:

| Показатель (SLI)             | Что это значит для бизнеса                          | Как измеряется |
|------------------------------|-----------------------------------------------------|----------------|
| Доступность сервиса          | Насколько часто клиент может получить ответ       | % запросов с HTTP 2xx от общего числа |
| Скорость обработки           | Сколько ждет клиент результата                     | Доля запросов, обработанных за ≤ 5 сек (например, p95 latency) |
| Надежность сохранения отчетов | Удается ли системе сохранить результат вычислений | % успешных записей отчетов на диск |


## Выполнение SLO, обязательств перед клиентами:
| Показатель                   | Цель (SLO)         | Факт (последние 28 дней) | Статус       |
|------------------------------|--------------------|--------------------------|--------------|
| Доступность                  | ≥ 99.5%            | 99.8%                    | Выполняется |
| Скорость (p95)               | ≤ 5 сек            | 4.2 сек                  | Выполняется |
| Сохранение отчетов           | ≥ 99.9%            | 100%                     | Выполняется |

### Предложить визуализировать данные, создать дашборб в Grafana, который будет показывать график по месяцам. 

## 3. Вашей DevOps-команде в этом году не выделили финансирование на построение системы сбора логов. Разработчики, в свою очередь, хотят видеть все ошибки, которые выдают их приложения. Какое решение вы можете предпринять в этой ситуации, чтобы разработчики получали ошибки приложения?

### Поскольку финансирования нет будем использовать open source решение, а именно Sentry и OpenSearch.

Примерно так будет выглядеть система мониторинга:

  - Sentry — для ошибок, исключений, трейсов
  - OpenSearch + Dashboards — для логов, поиска, анализа

Где будут храниться логи OpenSearch:

  - OpenSearch сохраняет их в виде **документов в индексах** (например, `app-logs-2025-04-05`)
  - Данные хранятся в **объектном хранилище или на локальных дисках нод кластера**


## 4. Вы, как опытный SRE, сделали мониторинг, куда вывели отображения выполнения SLA=99% по http кодам ответов. Вычисляете этот параметр по следующей формуле: summ_2xx_requests/summ_all_requests. Данный параметр не поднимается выше 70%, но при этом в вашей системе нет кодов ответа 5xx и 4xx. Где у вас ошибка?


### Формула *summ_2xx_requests/summ_all_requests* не учитывает все HTTP-запросы в знаменателе, 3хх и 1хх тоже необходимы.

```
(summ_1xx_requests + summ_2xx_requests + summ_3xx_requests)/summ_all_requests - вот такая формула верна.
```


## 5. Опишите основные плюсы и минусы pull и push систем мониторинга.


Выбор между pull и push определяет, кто инициирует передачу метрик: система мониторинга (pull) или источник данных (push).

- **Push**
  - Плюсы:
    - Агенты могут буферизовать метрики при обрыве связи и отправлять их позже, поэтому даже если канал связи не очень - все будет работать.
    - Можно выбирать: UDP для высоконагруженных систем или TCP  — в зависимости от критичности данных.
    - Масштабируемость в динамических средах.
    - Гибкость в управлении нагрузкой. Каждый источник может сам решать, какие метрики отправлять и с какой частотой, что снижает нагрузку на центральный сервер.
   - Минусы:
    - Риск потери данных при сбоях. Если агент упал до отправки, а буфер не был сохранен - данные потеряны (особенно при UDP).
    - Труднее централизованно управлять конфигурацией. Обновление частоты отправки или списка метрик требует изменения на каждом агенте, а не в одном месте.


Push — лучше там, где источники непостоянны, сеть ненадежна, или нужно минимизировать задержки в доставке.

- **Pull**
  - Плюсы:
    - Прозрачность и контроль. Мы точно знаем какие цели опрашиваются, когда и как часто.
    - Безопаснность. Можно использовать TLS, аутентификацию по токенам или mTLS. Все запросы инициируются изнутри доверенной зоны.
    - Удобная отладка. Достаточно открыть в браузере /metrics на целевом сервисе.
    - Данные доставляются по требованию. Нет риска потери из-за сбоя агента, если сервис жив, он ответит. Если нет, то это явно отобразится. 
  - Минусы:
    - Затруднен мониторинг динамически изменяющихся систем, таких как Kubernetes.
    - Нагрузка на центральный сервер при росте целей. 
  
Pull — лучше там, где важны прозрачность, безопасность и предсказуемость.


## 6. Какие из ниже перечисленных систем относятся к push модели, а какие к pull? А может есть гибридные?

## Классификация систем мониторинга: Push, Pull, Гибридные

| Система          | Модель       | Пояснение |
|------------------|-------------|----------|
| **Prometheus**   | 🔹 Pull      | Основная модель — **опрос (pull)**. Prometheus сам запрашивает метрики с целей через HTTP-эндпоинт `/metrics`. Поддерживает service discovery (Kubernetes, DNS и др.). |
| **TICK (InfluxDB)** | 🔹 Push     | Стек TICK (Telegraf, InfluxDB, Chronograf, Kapacitor) использует **push-модель**: Telegraf и приложения сами отправляют данные в InfluxDB по протоколам UDP/TCP/HTTP. |
| **Zabbix**       | 🔸 Гибридная | Поддерживает **оба подхода**:<br>– **Pull**: Zabbix Server опрашивает агенты или SNMP-устройства.<br>– **Push**: Агенты могут отправлять данные активно (Active Agent), а также приложения могут слать алерты через `zabbix_sender`. |
| **VictoriaMetrics** | 🔸 Гибридная | Сам по себе — **принимает данные по push** (совместим с Influx, Prometheus remote_write), но:<br>– Может работать как **Pull** (если используется как замена Prometheus, с scraping).<br>– Или как **Push** (при приёме через `/api/v1/write`).<br>→ Поддерживает оба режима. |
| **Nagios**       | 🔹 Pull      | Классическая **pull-система**: Nagios запускает проверки (через плагины) на своём сервере, опрашивая хосты по ICMP, SSH, HTTP, SNMP и т.д. Данные не отправляются сами — они запрашиваются. |

---

| Модель       | Системы |
|-------------|--------|
| **Pull**     | Prometheus, Nagios |
| **Push**     | TICK (InfluxDB) |
| **Гибридные**| Zabbix, VictoriaMetrics |

---
